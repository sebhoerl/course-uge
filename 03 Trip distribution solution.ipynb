{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890628d-71ba-4cbf-9dd6-13534aae4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy.linalg as la\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2448cf2-082f-49a3-9cc5-42f351cb0de8",
   "metadata": {},
   "source": [
    "# Trip distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96345766-dee9-4f25-bf09-7d7ef24e3ecd",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to learn how to work with simple gravity models for trip distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c3ac6-03c8-4361-97d0-ee8edc6e0804",
   "metadata": {},
   "source": [
    "First, let's load the population, commuting, and municipality data from the first exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cadca96-b0a0-4521-92a2-048b3c039fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employment = pd.read_parquet(\"data/employment.parquet\")\n",
    "df_commutes = pd.read_parquet(\"data/commutes.parquet\")\n",
    "df_municipalities = gpd.read_parquet(\"data/municipalities.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5472369-1850-4f02-acfb-4c93722b2bf3",
   "metadata": {},
   "source": [
    "**Task**: As before, reduce all data sets to the area of Île-de-France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648ff61-9537-40fe-a28c-df2c613a5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_departments = [\"75\", \"92\", \"93\", \"94\", \"95\", \"77\", \"91\", \"78\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4141fe-e58d-47c7-9237-efe9b71df885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "### SOLUTION START\n",
    "df_employment = df_employment[df_employment[\"municipality_id\"].str[:2].isin(idf_departments)]\n",
    "df_municipalities = df_municipalities[df_municipalities[\"municipality_id\"].str[:2].isin(idf_departments)]\n",
    "\n",
    "df_commutes = df_commutes[\n",
    "    df_commutes[\"origin_id\"].str[:2].isin(idf_departments) &\n",
    "    df_commutes[\"destination_id\"].str[:2].isin(idf_departments)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29c15a-4363-4ab8-8810-6a3e18caa833",
   "metadata": {},
   "source": [
    "**Task**: Keeping track of the order of the data will be important. Set up a fixed list of municipalities and adjust the indices of all data sets. Especially, take care of the commuting data set.\n",
    "\n",
    "Hint: Make use of `pd.MultiIndex.from_product`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca52964-8783-4417-b5b8-90651ac8213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "# municipalities = \n",
    "\n",
    "# df_emloyment = \n",
    "# df_commutes = \n",
    "\n",
    "### SOLUTION START\n",
    "municipalities = df_municipalities[\"municipality_id\"].unique()\n",
    "\n",
    "df_employment = df_employment.set_index(\"municipality_id\").reindex(municipalities)\n",
    "\n",
    "df_commutes = df_commutes.set_index([\"origin_id\", \"destination_id\"]).reindex(\n",
    "    pd.MultiIndex.from_product([municipalities, municipalities], names = [\"origin_id\", \"destination_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7d6880-9a63-471a-8004-21e1fae40e34",
   "metadata": {},
   "source": [
    "Have a look at your data sets after reindexing, do you notice anything special?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ace94f-d378-4a31-b7cf-492b54011b03",
   "metadata": {},
   "source": [
    "**Task**: How many flow values can we theoretically have (between all zones) in Île-de-France? For how many do we have actual values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460fe7c2-0cf6-45e0-9887-ac87562ce91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "### SOLUTION START\n",
    "len(df_commutes), np.count_nonzero(~df_commutes.isna()), np.count_nonzero(~df_commutes.isna()) / len(df_commutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7f61a-a0b0-4369-868c-3475f0c61b6d",
   "metadata": {},
   "source": [
    "**Task**: Replace missing values by zero (zero commuters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7371a1-b967-4417-b56f-ef3383d9e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "### SOLUTION START\n",
    "df_commutes[\"weight\"] = df_commutes[\"weight\"].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e987578-6c14-48f3-9efb-1e1967e09d74",
   "metadata": {},
   "source": [
    "## Friction term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cfed4c-fd72-4ae7-8330-619a8face9df",
   "metadata": {},
   "source": [
    "The first step in setting up our model is to obtain the friction term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5e53d-9be6-4ebc-a670-94e692f5b378",
   "metadata": {},
   "source": [
    "**Task**: The gravity model puts into relation different places in the study area. The friction term describes how easy it is to reach one municipality from another one. The first step is, therefore, to obtain the distances between all zones. Complete the following code to set up a distance matrix `distance_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ad2c2-a00f-46e7-b419-192af2b79759",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = df_municipalities[\"geometry\"].centroid\n",
    "centroids = np.array([centroids.x, centroids.y] ).T\n",
    "\n",
    "distance_matrix = np.zeros((len(municipalities), len(municipalities)))\n",
    "\n",
    "for k in range(len(municipalities)):\n",
    "    # Insert your code here\n",
    "    # distance_matrix[k,:] = # Calculate the Euclidean distance, you may also try numpy.linalg.norm\n",
    "    \n",
    "    ### SOLUTION START\n",
    "    distance_matrix[k,:] = la.norm(centroids[k] - centroids, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf31c994-bfe3-4bbb-bf3a-ba153a316503",
   "metadata": {},
   "source": [
    "Plot the distance matrix (it may take a while):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36613a-6ed5-4789-a8e2-9eb4f612c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8edf0",
   "metadata": {},
   "source": [
    "What do you notice in the plot? Can you explain the structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aab2bd-050d-44f5-9421-ba84326f4e8a",
   "metadata": {},
   "source": [
    "**Task**: Analogously to the distance matrix, we need a flow matrix indicating all observed movements (`weight`) between all zones. Obtain this matrix by transforming the commuting data set into a matrix.\n",
    "\n",
    "Hint: Have a look at `numpy.ndarray.reshape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87161748-b23b-4262-bc3c-ea4ea22985b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "# flow_matrix = \n",
    "\n",
    "### SOLUTION START\n",
    "flow_matrix = df_commutes[\"weight\"].values.reshape((len(municipalities), len(municipalities)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee370d5-f567-4dce-b873-de750015a50a",
   "metadata": {},
   "source": [
    "**Task**: Now we obtain the data to set up the friction model:\n",
    "- Bin the distances into about twenty distance bins and sum up the commuters you find in each distance bin\n",
    "- Plot how much flow occurs at every distance bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4193e8-0f7e-4977-9e17-8fb07dfd55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_friction = pd.DataFrame({\n",
    "    \"distance\": distance_matrix.flatten(),\n",
    "    \"flow\": flow_matrix.flatten()\n",
    "})\n",
    "\n",
    "distance_classes = np.arange(20) * 5000\n",
    "\n",
    "# Hint: Check numpy.digitize\n",
    "\n",
    "# Insert your code here\n",
    "\n",
    "### SOLUTION START\n",
    "df_friction[\"distance_class\"] = np.digitize(df_friction[\"distance\"], distance_classes)\n",
    "df_friction = df_friction.groupby(\"distance_class\")[\"flow\"].sum().reset_index()\n",
    "\n",
    "plt.plot(distance_classes * 1e-3, df_friction[\"flow\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3cb9f-32b9-450c-b1d7-14d0972324c5",
   "metadata": {},
   "source": [
    "**Task**: Now divide the obtained flow in each bin by the total flow, to obtain an empirical probability density function (pdf). Plot the function in absolute coordinates and with the probability logarithmized. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf35ccf-bc4c-481f-805f-bae23ffaa11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "# pdf = \n",
    "\n",
    "### SOLUTION START\n",
    "pdf = df_friction[\"flow\"].values / df_friction[\"flow\"].sum()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(distance_classes * 1e-3, pdf)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(distance_classes * 1e-3, np.log(pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7bf7fa-fcd3-4354-a325-6198fc629063",
   "metadata": {},
   "source": [
    "**Task**: In logarithmic space, manually (or automatically, if you like), fit a linear function on the graph that you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104531f-0767-4526-994e-75e80c7712e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here\n",
    "\n",
    "# a = ?\n",
    "# b = ?\n",
    "\n",
    "# logy = a + b * np.log(pdf)\n",
    "\n",
    "### SOLUTION START\n",
    "a = -0.9\n",
    "b = -1.02e-4\n",
    "\n",
    "logy = a + b * distance_classes\n",
    "\n",
    "plt.plot(distance_classes * 1e-3, np.log(pdf))\n",
    "plt.plot(distance_classes * 1e-3, logy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c13a0-5f11-451a-ba5f-15ab2f1c414d",
   "metadata": {},
   "source": [
    "**Task**: Now plot the initial data along with your fitted curve in linear space. How does you friction model look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a52435-cf8d-4ed9-bc64-476ab1ab2a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here\n",
    "\n",
    "### SOLUTION START\n",
    "a = -0.9\n",
    "b = -1.02e-4\n",
    "\n",
    "logy = a + b * distance_classes\n",
    "\n",
    "plt.plot(distance_classes * 1e-3, pdf)\n",
    "plt.plot(distance_classes * 1e-3, np.exp(logy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831f10c-0766-4fcb-8356-cd2684bbd5b2",
   "metadata": {},
   "source": [
    "**Task**: Based on your distance matrix and your friction model, calculate a friction matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619189e-509b-43d9-8ae8-b196ce0532df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here\n",
    "\n",
    "# friction_matrix =\n",
    "\n",
    "### SOLUTION START \n",
    "friction_matrix = np.exp(a + b * distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77797d53-de28-4897-b829-772888802297",
   "metadata": {},
   "source": [
    "## Double-constrained gravity model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570be0e9-4154-46da-8644-c85b56c0a900",
   "metadata": {},
   "source": [
    "Let's move on to the double-constrained model. In that model, both the origin and destination flows $O_i$ and $D_j$ are known and we aim to automatically find the attraction and production terms $A_j$ and $P_i$.\n",
    "\n",
    "The model is defined as follows:\n",
    "\n",
    "$$\n",
    "F_{ij} = \\frac{O_i \\cdot D_i}{(\\sum_i P_i \\cdot \\rho_{ij})\\cdot (\\sum_j A_j \\cdot \\rho_{ij})}\n",
    "$$\n",
    "\n",
    "the attraction and production terms are obtained by iteratively executing:\n",
    "\n",
    "$$\n",
    "P_i = \\frac{O_i}{\\sum_j A_j \\cdot \\rho_{ij}}\n",
    "$$\n",
    "$$\n",
    "A_j = \\frac{D_j}{\\sum_i P_i \\cdot \\rho_{ij}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b4b24-540e-4382-9728-63a6b6c424f5",
   "metadata": {},
   "source": [
    "**Task**: Implement the double-constrained gravity model to calculate the production and attraction terms. Optionally, you may plot the delta of the production and attraction terms in every iteration to observe convergence. The model should be well converged after 25 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4aaf40-2dc1-4eb2-ae1a-cd17990cde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert code here\n",
    "\n",
    "# origins = # Format properly\n",
    "# destinations = # Format properly\n",
    "\n",
    "# production = # Initialize to one\n",
    "# attraction = # Initialize to one\n",
    "\n",
    "# for iteration in range(500):\n",
    "#    for i in range(len(municipalities)):\n",
    "        # ...\n",
    "\n",
    "#    for j in range(len(municipalities)):\n",
    "        # ...\n",
    "\n",
    "### SOLUTION START \n",
    "origins = np.sum(flow_matrix, axis = 1)\n",
    "destinations = np.sum(flow_matrix, axis = 0)\n",
    "\n",
    "production = np.ones((len(municipalities),))\n",
    "attraction = np.ones((len(municipalities),))\n",
    "\n",
    "delta_production = []\n",
    "delta_attraction = []\n",
    "\n",
    "for iteration in range(25):\n",
    "    delta_production_iteration = []\n",
    "    delta_attraction_iteration = []\n",
    "\n",
    "    for i in range(len(municipalities)):\n",
    "        update = origins[i] / np.sum(attraction * friction_matrix[i,:])\n",
    "        delta_production_iteration.append(update - production[i])\n",
    "        production[i] = update\n",
    "    \n",
    "    for j in range(len(municipalities)):\n",
    "        update = destinations[j] / np.sum(production * friction_matrix[:,j])\n",
    "        delta_attraction_iteration.append(update - attraction[j])\n",
    "        attraction[j] = update   \n",
    "\n",
    "    delta_production.append(np.max(np.abs(delta_production_iteration)))\n",
    "    delta_attraction.append(np.max(np.abs(delta_attraction_iteration)))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(delta_attraction)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(delta_production)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5c4942-8292-4f4d-b2bc-2eefefae8934",
   "metadata": {},
   "source": [
    "**Task**: Calculate the resulting flows of your model. Compare the flows with the reference data, and also compare origin and destination flows in two additional plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf71b3-1408-4cfb-b4f0-8e649bb78e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert code here\n",
    "\n",
    "### SOLUTION START \n",
    "F = np.copy(friction_matrix)\n",
    "\n",
    "for i in range(len(municipalities)):\n",
    "    F[i,:] *= origins[i] / np.sum(attraction * friction_matrix[i,:])\n",
    "\n",
    "for j in range(len(municipalities)):\n",
    "    F[:,j] *= destinations[j] / np.sum(production * friction_matrix[:,j])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(flow_matrix.flatten(), F.flatten(), \".\")\n",
    "plt.plot([0, np.max(flow_matrix)], [0, np.max(flow_matrix)], \"k--\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.sum(flow_matrix, axis = 1), np.sum(F, axis = 1), \".\")\n",
    "plt.plot([0, np.max(np.sum(flow_matrix, axis = 1))], [0, np.max(np.sum(flow_matrix, axis = 1))], \"k--\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.sum(flow_matrix, axis = 0), np.sum(F, axis = 0), \".\")\n",
    "plt.plot([0, np.max(np.sum(flow_matrix, axis = 0))], [0, np.max(np.sum(flow_matrix, axis = 0))], \"k--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d0b79-2f82-42c8-9ce3-dec9dab8fe21",
   "metadata": {},
   "source": [
    "What do you observe? Which municipalities could be the outliers on the bottom of the flow comparison?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7058b-0c27-435f-a8b7-5ffa30f5ff5d",
   "metadata": {},
   "source": [
    "**Task**: Try to estimate a new model using the following modified friction term:\n",
    "\n",
    "$$\n",
    "F'_{ij} = \\begin{cases}\n",
    "    F_{ij} & \\text{if} \\ i \\neq j \\\\\n",
    "    F_{ij} + \\gamma & \\text{if} \\  i = j\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Which parameter $\\gamma$ works best?\n",
    "\n",
    "Hint: Keep your existing friction matrix in `friction_matrix` and create new matrices on the fly for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01608a5f-6bc3-4e6d-9a58-70eef58d72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert code here\n",
    "\n",
    "### SOLUTION START\n",
    "gammas = np.linspace(0, 10, 5)\n",
    "\n",
    "for gamma in gammas:\n",
    "    updated_friction_matrix = friction_matrix + np.eye(len(municipalities)) * gamma\n",
    "\n",
    "    origins = np.sum(flow_matrix, axis = 1)\n",
    "    destinations = np.sum(flow_matrix, axis = 0)\n",
    "    \n",
    "    production = np.ones((len(municipalities),))\n",
    "    attraction = np.ones((len(municipalities),))\n",
    "    \n",
    "    for iteration in range(25):\n",
    "        for i in range(len(municipalities)):\n",
    "            production[i] = origins[i] / np.sum(attraction * updated_friction_matrix[i,:])\n",
    "        \n",
    "        for j in range(len(municipalities)):\n",
    "            attraction[j] = destinations[j] / np.sum(production * updated_friction_matrix[:,j])\n",
    "\n",
    "    F = np.copy(updated_friction_matrix)\n",
    "\n",
    "    for i in range(len(municipalities)):\n",
    "        F[i,:] *= origins[i] / np.sum(attraction * updated_friction_matrix[i,:])\n",
    "    \n",
    "    for j in range(len(municipalities)):\n",
    "        F[:,j] *= destinations[j] / np.sum(production * updated_friction_matrix[:,j])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"gamma={}\".format(gamma))\n",
    "    plt.plot(flow_matrix.flatten(), F.flatten(), \".\")\n",
    "    plt.plot([0, np.max(flow_matrix)], [0, np.max(flow_matrix)], \"k--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e71d62-280b-4d5a-aa5c-9f3992a51e4c",
   "metadata": {},
   "source": [
    "**Task**: Do you remeber the initial data frame `df_commutes`? Add a new column to this data frame into which you write your latest modeling results. Show the data frame. Calculate how many zero-cells have been filled with a non-zero value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b81b8a-d166-4b1f-9ee1-f3494c0e701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert code here\n",
    "\n",
    "### SOLUTION START\n",
    "df_flow = df_commutes.copy()\n",
    "df_flow[\"model\"] = F.reshape((-1,))\n",
    "df_flow\n",
    "\n",
    "np.mean((df_flow[\"weight\"] == 0.0) & (df_flow[\"model\"] != 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e45e13e",
   "metadata": {},
   "source": [
    "**Task**: On map, show the commuting outflow from Melun like in the previous notebook, but using the model data. For better visibility, put the maximum value of the color scale to 1000 or 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "### SOLUTION START\n",
    "df = df_flow.copy().reset_index()\n",
    "df = df[df[\"origin_id\"] == \"77288\"]\n",
    "df = df.groupby(\"destination_id\")[\"weight\"].sum().reset_index()\n",
    "df = df.rename(columns = { \"destination_id\": \"municipality_id\" })\n",
    "\n",
    "pd.merge(df_municipalities[df_municipalities[\"municipality_id\"].str[:2].isin([\n",
    "    \"75\", \"92\", \"93\", \"94\", \"95\", \"77\", \"91\", \"78\"\n",
    "])], df).plot(\"weight\", legend = True, vmax = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d353958-cdb5-4fb0-9242-3fbf0682dd7a",
   "metadata": {},
   "source": [
    "Save the data set for the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc70c4-ff0a-4b56-8aa4-6bb546761f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flow.to_parquet(\"data/flow.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a6a262-3801-4a82-aeba-6656b5e8c4b0",
   "metadata": {},
   "source": [
    "**Congratulations!** You can now solve exercise 2.3 of the course project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
